{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Festeja Kids - Integra√ß√£o com APIs de IA\n",
    "\n",
    "**Notebook para testar e usar APIs de IA no Google Colab**\n",
    "\n",
    "Este notebook demonstra como integrar diferentes APIs de IA para automatizar tarefas do Festeja Kids.\n",
    "\n",
    "---\n",
    "\n",
    "## üîê Configura√ß√£o de API Keys\n",
    "\n",
    "**IMPORTANTE**: Nunca exponha suas chaves API no c√≥digo!\n",
    "\n",
    "### Como adicionar chaves de forma segura no Colab:\n",
    "\n",
    "1. Clique no √≠cone üîë (chave) na barra lateral esquerda\n",
    "2. Clique em **+ Add new secret**\n",
    "3. Adicione cada chave:\n",
    "   - `MANUS_API_KEY` = `FESTEJA-KIDS2-API-241120250201`\n",
    "   - `OPENAI_API_KEY` = sua chave OpenAI\n",
    "   - `GEMINI_API_KEY` = sua chave Google Gemini\n",
    "   - etc.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Instala√ß√£o de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar todas as bibliotecas necess√°rias\n",
    "!pip install -q openai google-generativeai anthropic requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîë Carregar API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "# Carregar chaves de forma segura\n",
    "try:\n",
    "    MANUS_API_KEY = userdata.get('MANUS_API_KEY')\n",
    "    print(\"‚úÖ Manus API Key carregada\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Manus API Key n√£o encontrada. Adicione em Secrets.\")\n",
    "    MANUS_API_KEY = None\n",
    "\n",
    "try:\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "    print(\"‚úÖ OpenAI API Key carregada\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è OpenAI API Key n√£o encontrada. Adicione em Secrets.\")\n",
    "    OPENAI_API_KEY = None\n",
    "\n",
    "try:\n",
    "    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
    "    print(\"‚úÖ Gemini API Key carregada\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Gemini API Key n√£o encontrada. Adicione em Secrets.\")\n",
    "    GEMINI_API_KEY = None\n",
    "\n",
    "print(\"\\n‚úÖ Configura√ß√£o conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ 1. API Manus (J√° Configurada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def chamar_manus_llm(mensagem, sistema=\"Voc√™ √© um assistente de festas infantis.\"):\n",
    "    \"\"\"\n",
    "    Chama a API Manus LLM\n",
    "    \"\"\"\n",
    "    if not MANUS_API_KEY:\n",
    "        return \"‚ùå API Key do Manus n√£o configurada\"\n",
    "    \n",
    "    url = \"https://forge.manus.im/llm/chat\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {MANUS_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": sistema},\n",
    "            {\"role\": \"user\", \"content\": mensagem}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json()['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Erro: {str(e)}\"\n",
    "\n",
    "# Teste\n",
    "print(\"üéâ Testando API Manus...\\n\")\n",
    "resposta = chamar_manus_llm(\"Sugira 5 temas de festa para crian√ßas de 5 anos\")\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ 2. OpenAI API (GPT-4 / GPT-3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def chamar_openai(mensagem, modelo=\"gpt-3.5-turbo\", sistema=\"Voc√™ √© um especialista em festas infantis.\"):\n",
    "    \"\"\"\n",
    "    Chama a API OpenAI\n",
    "    \"\"\"\n",
    "    if not OPENAI_API_KEY:\n",
    "        return \"‚ùå API Key da OpenAI n√£o configurada\"\n",
    "    \n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=modelo,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sistema},\n",
    "                {\"role\": \"user\", \"content\": mensagem}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Erro: {str(e)}\"\n",
    "\n",
    "# Teste\n",
    "print(\"ü§ñ Testando OpenAI...\\n\")\n",
    "resposta = chamar_openai(\"Liste 10 atividades divertidas para festa de Frozen\")\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåü 3. Google Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "def chamar_gemini(mensagem):\n",
    "    \"\"\"\n",
    "    Chama a API Google Gemini\n",
    "    \"\"\"\n",
    "    if not GEMINI_API_KEY:\n",
    "        return \"‚ùå API Key do Gemini n√£o configurada\"\n",
    "    \n",
    "    genai.configure(api_key=GEMINI_API_KEY)\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(mensagem)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Erro: {str(e)}\"\n",
    "\n",
    "# Teste\n",
    "print(\"üåü Testando Google Gemini...\\n\")\n",
    "resposta = chamar_gemini(\"Crie um card√°pio saud√°vel para festa infantil com 50 crian√ßas\")\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Casos de Uso Pr√°ticos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù Caso 1: Gerador de Descri√ß√µes de Festas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_descricao_festa(tema, idade, convidados, api=\"manus\"):\n",
    "    \"\"\"\n",
    "    Gera descri√ß√£o de marketing para uma festa\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Crie uma descri√ß√£o de marketing atrativa e profissional para uma festa infantil com:\n",
    "    \n",
    "    - Tema: {tema}\n",
    "    - Idade da crian√ßa: {idade} anos\n",
    "    - N√∫mero de convidados: {convidados}\n",
    "    \n",
    "    A descri√ß√£o deve:\n",
    "    1. Ter 2-3 par√°grafos\n",
    "    2. Destacar a divers√£o e seguran√ßa\n",
    "    3. Mencionar atividades t√≠picas do tema\n",
    "    4. Ser envolvente e profissional\n",
    "    \"\"\"\n",
    "    \n",
    "    if api == \"manus\":\n",
    "        return chamar_manus_llm(prompt)\n",
    "    elif api == \"openai\":\n",
    "        return chamar_openai(prompt)\n",
    "    elif api == \"gemini\":\n",
    "        return chamar_gemini(prompt)\n",
    "\n",
    "# Teste\n",
    "print(\"=\" * 60)\n",
    "print(\"üìù GERADOR DE DESCRI√á√ïES DE FESTAS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "descricao = gerar_descricao_festa(\n",
    "    tema=\"Patrulha Canina\",\n",
    "    idade=4,\n",
    "    convidados=30,\n",
    "    api=\"manus\"  # Trocar para \"openai\" ou \"gemini\" se preferir\n",
    ")\n",
    "\n",
    "print(f\"\\n{descricao}\\n\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Caso 2: Sugest√£o de Atividades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sugerir_atividades(tema, idade, duracao_horas=3):\n",
    "    \"\"\"\n",
    "    Sugere atividades para a festa\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Sugira um cronograma de atividades para uma festa infantil de {tema} para crian√ßas de {idade} anos.\n",
    "    \n",
    "    A festa dura {duracao_horas} horas.\n",
    "    \n",
    "    Para cada atividade, forne√ßa:\n",
    "    1. Nome da atividade\n",
    "    2. Dura√ß√£o estimada\n",
    "    3. Materiais necess√°rios\n",
    "    4. Breve descri√ß√£o\n",
    "    \n",
    "    Organize em ordem cronol√≥gica.\n",
    "    \"\"\"\n",
    "    \n",
    "    return chamar_manus_llm(prompt)\n",
    "\n",
    "# Teste\n",
    "print(\"=\" * 60)\n",
    "print(\"üí° SUGEST√ÉO DE ATIVIDADES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "atividades = sugerir_atividades(\n",
    "    tema=\"Super-Her√≥is\",\n",
    "    idade=6,\n",
    "    duracao_horas=3\n",
    ")\n",
    "\n",
    "print(f\"\\n{atividades}\\n\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí∞ Caso 3: Gerador de Or√ßamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_orcamento(tema, convidados, orcamento_total):\n",
    "    \"\"\"\n",
    "    Gera or√ßamento detalhado para a festa\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Crie um or√ßamento detalhado para uma festa infantil com:\n",
    "    \n",
    "    - Tema: {tema}\n",
    "    - N√∫mero de convidados: {convidados}\n",
    "    - Or√ßamento total: R$ {orcamento_total:,.2f}\n",
    "    \n",
    "    Distribua o or√ßamento nas seguintes categorias:\n",
    "    1. Decora√ß√£o (30%)\n",
    "    2. Alimenta√ß√£o (35%)\n",
    "    3. Entretenimento (20%)\n",
    "    4. Lembrancinhas (10%)\n",
    "    5. Outros (5%)\n",
    "    \n",
    "    Para cada categoria:\n",
    "    - Valor alocado\n",
    "    - Lista de itens espec√≠ficos\n",
    "    - Quantidade estimada\n",
    "    - Custo unit√°rio aproximado\n",
    "    \n",
    "    Formate como uma tabela clara.\n",
    "    \"\"\"\n",
    "    \n",
    "    return chamar_manus_llm(prompt)\n",
    "\n",
    "# Teste\n",
    "print(\"=\" * 60)\n",
    "print(\"üí∞ GERADOR DE OR√áAMENTO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "orcamento = gerar_orcamento(\n",
    "    tema=\"Frozen\",\n",
    "    convidados=50,\n",
    "    orcamento_total=5000.00\n",
    ")\n",
    "\n",
    "print(f\"\\n{orcamento}\\n\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Caso 4: An√°lise de Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def analisar_feedback(texto_feedback):\n",
    "    \"\"\"\n",
    "    Analisa sentimento e extrai insights de feedback\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Analise o seguinte feedback de uma festa infantil:\n",
    "    \n",
    "    \"{texto_feedback}\"\n",
    "    \n",
    "    Retorne APENAS um JSON v√°lido com:\n",
    "    {{\n",
    "        \"sentimento\": \"positivo/neutro/negativo\",\n",
    "        \"score\": 0-10,\n",
    "        \"pontos_fortes\": [\"lista de pontos positivos\"],\n",
    "        \"pontos_fracos\": [\"lista de pontos negativos\"],\n",
    "        \"acao_recomendada\": \"o que fazer com base no feedback\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    resposta = chamar_manus_llm(prompt)\n",
    "    \n",
    "    try:\n",
    "        # Tentar extrair JSON da resposta\n",
    "        inicio = resposta.find('{')\n",
    "        fim = resposta.rfind('}') + 1\n",
    "        json_str = resposta[inicio:fim]\n",
    "        return json.loads(json_str)\n",
    "    except:\n",
    "        return {\"erro\": \"N√£o foi poss√≠vel parsear JSON\", \"resposta_bruta\": resposta}\n",
    "\n",
    "# Teste\n",
    "print(\"=\" * 60)\n",
    "print(\"üìä AN√ÅLISE DE FEEDBACK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "feedback_exemplo = \"\"\"\n",
    "A festa foi maravilhosa! As crian√ßas adoraram a decora√ß√£o do tema Frozen.\n",
    "A comida estava deliciosa e chegou na hora certa. A √∫nica coisa que poderia\n",
    "melhorar seria ter mais op√ß√µes de brincadeiras ao ar livre, pois estava um\n",
    "dia lindo e as crian√ßas queriam brincar fora. No geral, super recomendo!\n",
    "\"\"\"\n",
    "\n",
    "analise = analisar_feedback(feedback_exemplo)\n",
    "print(f\"\\n{json.dumps(analise, indent=2, ensure_ascii=False)}\\n\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üé® Caso 5: Gerador de Paleta de Cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_paleta_cores(tema):\n",
    "    \"\"\"\n",
    "    Gera paleta de cores para decora√ß√£o\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Sugira uma paleta de cores para decora√ß√£o de festa infantil com tema {tema}.\n",
    "    \n",
    "    Forne√ßa:\n",
    "    1. Cor principal (com c√≥digo hexadecimal)\n",
    "    2. Cor secund√°ria (com c√≥digo hexadecimal)\n",
    "    3. Cor de destaque/acento (com c√≥digo hexadecimal)\n",
    "    4. Cor neutra (com c√≥digo hexadecimal)\n",
    "    5. Sugest√µes de como usar cada cor na decora√ß√£o\n",
    "    \n",
    "    Formato:\n",
    "    Cor Principal: [nome] (#XXXXXX) - [uso]\n",
    "    \"\"\"\n",
    "    \n",
    "    return chamar_manus_llm(prompt)\n",
    "\n",
    "# Teste\n",
    "print(\"=\" * 60)\n",
    "print(\"üé® GERADOR DE PALETA DE CORES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "paleta = gerar_paleta_cores(\"Unic√≥rnio\")\n",
    "print(f\"\\n{paleta}\\n\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí¨ Caso 6: Chatbot de Atendimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_atendimento(mensagem, historico=[]):\n",
    "    \"\"\"\n",
    "    Simula chatbot de atendimento\n",
    "    \"\"\"\n",
    "    sistema = \"\"\"\n",
    "    Voc√™ √© um atendente virtual da Festeja Kids, empresa de festas infantis.\n",
    "    \n",
    "    Seja cordial, prestativo e profissional.\n",
    "    \n",
    "    Seu objetivo √© coletar as seguintes informa√ß√µes:\n",
    "    1. Nome do cliente\n",
    "    2. Telefone\n",
    "    3. Data desejada para a festa\n",
    "    4. Tema preferido\n",
    "    5. N√∫mero de convidados\n",
    "    6. Or√ßamento aproximado\n",
    "    \n",
    "    Fa√ßa perguntas uma de cada vez.\n",
    "    Quando tiver todas as informa√ß√µes, resuma e pergunte se pode agendar uma visita.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Construir hist√≥rico para contexto\n",
    "    mensagens_contexto = \"\\n\".join([\n",
    "        f\"{msg['role']}: {msg['content']}\" \n",
    "        for msg in historico\n",
    "    ])\n",
    "    \n",
    "    prompt_completo = f\"\"\"\n",
    "    Hist√≥rico da conversa:\n",
    "    {mensagens_contexto}\n",
    "    \n",
    "    Cliente: {mensagem}\n",
    "    \n",
    "    Responda como atendente:\n",
    "    \"\"\"\n",
    "    \n",
    "    resposta = chamar_manus_llm(prompt_completo, sistema=sistema)\n",
    "    \n",
    "    # Atualizar hist√≥rico\n",
    "    historico.append({\"role\": \"cliente\", \"content\": mensagem})\n",
    "    historico.append({\"role\": \"atendente\", \"content\": resposta})\n",
    "    \n",
    "    return resposta, historico\n",
    "\n",
    "# Teste - Simula√ß√£o de conversa\n",
    "print(\"=\" * 60)\n",
    "print(\"üí¨ CHATBOT DE ATENDIMENTO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "historico = []\n",
    "\n",
    "# Mensagem 1\n",
    "print(\"\\nüë§ Cliente: Ol√°, gostaria de fazer uma festa para minha filha\\n\")\n",
    "resposta, historico = chatbot_atendimento(\n",
    "    \"Ol√°, gostaria de fazer uma festa para minha filha\",\n",
    "    historico\n",
    ")\n",
    "print(f\"ü§ñ Atendente: {resposta}\\n\")\n",
    "\n",
    "# Mensagem 2\n",
    "print(\"üë§ Cliente: Meu nome √© Maria Silva\\n\")\n",
    "resposta, historico = chatbot_atendimento(\n",
    "    \"Meu nome √© Maria Silva\",\n",
    "    historico\n",
    ")\n",
    "print(f\"ü§ñ Atendente: {resposta}\\n\")\n",
    "\n",
    "# Mensagem 3\n",
    "print(\"üë§ Cliente: (11) 98765-4321\\n\")\n",
    "resposta, historico = chatbot_atendimento(\n",
    "    \"(11) 98765-4321\",\n",
    "    historico\n",
    ")\n",
    "print(f\"ü§ñ Atendente: {resposta}\\n\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Compara√ß√£o de APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def comparar_apis(prompt):\n",
    "    \"\"\"\n",
    "    Compara velocidade e qualidade das APIs\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"üìä COMPARA√á√ÉO DE APIs\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nPrompt: {prompt}\\n\")\n",
    "    \n",
    "    # Manus\n",
    "    if MANUS_API_KEY:\n",
    "        print(\"\\nüéØ MANUS:\")\n",
    "        inicio = time.time()\n",
    "        resposta = chamar_manus_llm(prompt)\n",
    "        tempo = time.time() - inicio\n",
    "        print(f\"‚è±Ô∏è Tempo: {tempo:.2f}s\")\n",
    "        print(f\"üìù Resposta: {resposta[:200]}...\\n\")\n",
    "    \n",
    "    # OpenAI\n",
    "    if OPENAI_API_KEY:\n",
    "        print(\"\\nü§ñ OPENAI (GPT-3.5):\")\n",
    "        inicio = time.time()\n",
    "        resposta = chamar_openai(prompt, modelo=\"gpt-3.5-turbo\")\n",
    "        tempo = time.time() - inicio\n",
    "        print(f\"‚è±Ô∏è Tempo: {tempo:.2f}s\")\n",
    "        print(f\"üìù Resposta: {resposta[:200]}...\\n\")\n",
    "    \n",
    "    # Gemini\n",
    "    if GEMINI_API_KEY:\n",
    "        print(\"\\nüåü GEMINI:\")\n",
    "        inicio = time.time()\n",
    "        resposta = chamar_gemini(prompt)\n",
    "        tempo = time.time() - inicio\n",
    "        print(f\"‚è±Ô∏è Tempo: {tempo:.2f}s\")\n",
    "        print(f\"üìù Resposta: {resposta[:200]}...\\n\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# Teste\n",
    "comparar_apis(\"Liste 5 temas de festa infantil populares em 2025\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Exportar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Exemplo: Gerar m√∫ltiplas descri√ß√µes e salvar em Excel\n",
    "temas = [\n",
    "    {\"tema\": \"Frozen\", \"idade\": 5, \"convidados\": 30},\n",
    "    {\"tema\": \"Patrulha Canina\", \"idade\": 4, \"convidados\": 25},\n",
    "    {\"tema\": \"Super-Her√≥is\", \"idade\": 6, \"convidados\": 40},\n",
    "    {\"tema\": \"Unic√≥rnio\", \"idade\": 5, \"convidados\": 35},\n",
    "    {\"tema\": \"Dinossauros\", \"idade\": 7, \"convidados\": 45},\n",
    "]\n",
    "\n",
    "resultados = []\n",
    "\n",
    "print(\"üîÑ Gerando descri√ß√µes para m√∫ltiplos temas...\\n\")\n",
    "\n",
    "for item in temas:\n",
    "    print(f\"‚è≥ Processando: {item['tema']}...\")\n",
    "    descricao = gerar_descricao_festa(\n",
    "        tema=item['tema'],\n",
    "        idade=item['idade'],\n",
    "        convidados=item['convidados'],\n",
    "        api=\"manus\"\n",
    "    )\n",
    "    \n",
    "    resultados.append({\n",
    "        \"Tema\": item['tema'],\n",
    "        \"Idade\": item['idade'],\n",
    "        \"Convidados\": item['convidados'],\n",
    "        \"Descri√ß√£o\": descricao\n",
    "    })\n",
    "\n",
    "# Criar DataFrame\n",
    "df = pd.DataFrame(resultados)\n",
    "\n",
    "# Salvar em Excel\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f\"Festeja_Kids_Descricoes_IA_{timestamp}.xlsx\"\n",
    "df.to_excel(filename, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Arquivo salvo: {filename}\")\n",
    "print(f\"\\nüì• Fa√ßa o download no menu 'Arquivos' do Colab\\n\")\n",
    "\n",
    "# Mostrar preview\n",
    "print(\"üìã Preview:\")\n",
    "print(df[['Tema', 'Idade', 'Convidados']].to_string(index=False))\n",
    "\n",
    "# Download autom√°tico\n",
    "from google.colab import files\n",
    "files.download(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Pr√≥ximos Passos\n",
    "\n",
    "1. **Teste diferentes APIs** e compare resultados\n",
    "2. **Ajuste os prompts** para obter melhores respostas\n",
    "3. **Integre no backend** do Festeja Kids\n",
    "4. **Monitore custos** de cada API\n",
    "5. **Crie workflows automatizados** combinando m√∫ltiplas APIs\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Recursos\n",
    "\n",
    "- **Guia Completo**: `GUIA_INTEGRACAO_APIs.md`\n",
    "- **Documenta√ß√£o Manus**: https://docs.manus.im\n",
    "- **OpenAI Docs**: https://platform.openai.com/docs\n",
    "- **Google AI Studio**: https://makersuite.google.com\n",
    "\n",
    "---\n",
    "\n",
    "**Desenvolvido para Festeja Kids 2.0**  \n",
    "**√öltima Atualiza√ß√£o:** 24 de novembro de 2025"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Festeja_Kids_APIs_IA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
